#!/usr/bin/env python
# -*- coding: utf-8 -*-

import threading
import time
import numpy as np
import pyaudio
import tempfile
import os
import wave
from collections import deque
import audioop

class WakeWordDetector:
    """å…è´¹çš„å”¤é†’è¯æ£€æµ‹æ¨¡å— - ä¸“é—¨æ£€æµ‹'ä½ å¥½å°æ™º'"""
    DEFAULT_WAKE_WORD = "ä½ å¥½å°æ™º"
    def __init__(self, wake_word="ä½ å¥½å°æ™º", callback=None,
                 format=pyaudio.paInt16, channels=1, rate=16000, chunk=1024,
                 sensitivity=0.6):
        """
        åˆå§‹åŒ–å”¤é†’è¯æ£€æµ‹å™¨
        
        å‚æ•°:
            wake_word: å”¤é†’è¯ï¼ˆç›®å‰æ”¯æŒ"ä½ å¥½å°æ™º"ï¼‰
            callback: æ£€æµ‹åˆ°å”¤é†’è¯æ—¶çš„å›è°ƒå‡½æ•°
            format: éŸ³é¢‘æ ¼å¼
            channels: å£°é“æ•°
            rate: é‡‡æ ·ç‡
            chunk: æ¯æ¬¡è¯»å–çš„å¸§æ•°
            sensitivity: æ£€æµ‹çµæ•åº¦ (0.0-1.0)
        """
        self.wake_word = wake_word
        self.callback = callback
        self.format = format
        self.channels = channels
        self.rate = rate
        self.chunk = chunk
        self.sensitivity = sensitivity
        
        self.listening = False
        self.listen_thread = None
        self.audio = pyaudio.PyAudio()
        self.enabled = False
        
        # éŸ³é¢‘ç¼“å†²åŒºç”¨äºè¿ç»­æ£€æµ‹
        self.audio_buffer = deque(maxlen=int(self.rate * 3 / self.chunk))  # 3ç§’ç¼“å†²
        self.detection_buffer = []
        
        # åˆå§‹åŒ–æ£€æµ‹æ–¹æ³•
        self._init_speech_recognition()
        
        if not self.enabled:
            self._init_simple_pattern_detection()
    
    def _init_speech_recognition(self):
        """å°è¯•ä½¿ç”¨è¯­éŸ³è¯†åˆ«åº“è¿›è¡Œå”¤é†’è¯æ£€æµ‹"""
        try:
            import speech_recognition as sr
            self.recognizer = sr.Recognizer()
            self.microphone = sr.Microphone()
            
            # æ ¡å‡†ç¯å¢ƒå™ªéŸ³
            print("æ­£åœ¨æ ¡å‡†ç¯å¢ƒå™ªéŸ³...")
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=1)
            
            self.enabled = True
            self.detection_method = "speech_recognition"
            print(f"âœ… ä½¿ç”¨è¯­éŸ³è¯†åˆ«æ£€æµ‹å”¤é†’è¯: '{self.wake_word}'")
            
        except ImportError:
            print("speech_recognition åº“æœªå®‰è£…")
            print("å®‰è£…æ–¹æ³•: pip install SpeechRecognition pyaudio")
        except Exception as e:
            print(f"åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
    
    def _init_simple_pattern_detection(self):
        """ä½¿ç”¨ç®€å•çš„éŸ³é¢‘æ¨¡å¼æ£€æµ‹ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ"""
        self.detection_method = "pattern"
        
        # è¯­éŸ³æ´»åŠ¨æ£€æµ‹å‚æ•°
        self.energy_threshold = 2000
        self.zero_crossing_threshold = 50
        self.min_speech_duration = 0.5  # æœ€çŸ­è¯­éŸ³æ—¶é•¿
        self.max_speech_duration = 3.0  # æœ€é•¿è¯­éŸ³æ—¶é•¿
        
        # æ£€æµ‹çŠ¶æ€
        self.speech_started = False
        self.speech_start_time = 0
        self.last_detection_time = 0
        self.detection_cooldown = 3.0  # æ£€æµ‹å†·å´æ—¶é—´
        
        self.enabled = True
        print(f"âœ… ä½¿ç”¨éŸ³é¢‘æ¨¡å¼æ£€æµ‹å”¤é†’è¯: '{self.wake_word}'")
        print("ğŸ’¡ æç¤º: è¯·æ¸…æ™°åœ°è¯´å‡ºå”¤é†’è¯ï¼Œé¿å…èƒŒæ™¯å™ªéŸ³")
    
    def start(self):
        """å¼€å§‹ç›‘å¬å”¤é†’è¯"""
        if not self.enabled:
            print("âŒ å”¤é†’è¯åŠŸèƒ½æœªå¯ç”¨")
            return False
        
        if self.listening:
            return True
        
        self.listening = True
        self.listen_thread = threading.Thread(target=self._listen)
        self.listen_thread.daemon = True
        self.listen_thread.start()
        
        print(f"ğŸ§ å¼€å§‹ç›‘å¬å”¤é†’è¯ ({self.detection_method}): '{self.wake_word}'")
        return True
    
    def _listen(self):
        """ç›‘å¬çº¿ç¨‹"""
        if self.detection_method == "speech_recognition":
            self._listen_with_speech_recognition()
        else:
            self._listen_with_pattern_detection()
    
    def _listen_with_speech_recognition(self):
        """ä½¿ç”¨è¯­éŸ³è¯†åˆ«è¿›è¡Œç›‘å¬"""
        import speech_recognition as sr
        
        print("ğŸ¤ è¯­éŸ³è¯†åˆ«ç›‘å¬å·²å¯åŠ¨...")
        
        while self.listening:
            try:
                # è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´ï¼Œé¿å…é˜»å¡å¤ªä¹…
                with self.microphone as source:
                    # ç›‘å¬éŸ³é¢‘ï¼Œè¶…æ—¶1ç§’
                    audio = self.recognizer.listen(source, timeout=1, phrase_time_limit=3)
                
                try:
                    # ä½¿ç”¨Google Web Speech APIï¼ˆå…è´¹ä½†æœ‰é™åˆ¶ï¼‰
                    text = self.recognizer.recognize_google(audio, language='zh-CN')
                    print(f"ğŸ” è¯†åˆ«åˆ°: {text}")
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å”¤é†’è¯
                    if self._check_wake_word_match(text):
                        print(f"ğŸ¯ æ£€æµ‹åˆ°å”¤é†’è¯: '{self.wake_word}'")
                        self._trigger_callback()
                        
                except sr.UnknownValueError:
                    # æ— æ³•è¯†åˆ«è¯­éŸ³ï¼Œç»§ç»­ç›‘å¬
                    pass
                except sr.RequestError as e:
                    print(f"âš ï¸ è¯­éŸ³è¯†åˆ«æœåŠ¡é”™è¯¯: {e}")
                    # åˆ‡æ¢åˆ°å¤‡ç”¨æ–¹æ¡ˆ
                    print("ğŸ”„ åˆ‡æ¢åˆ°éŸ³é¢‘æ¨¡å¼æ£€æµ‹...")
                    self._init_simple_pattern_detection()
                    self._listen_with_pattern_detection()
                    break
                    
            except sr.WaitTimeoutError:
                # è¶…æ—¶ç»§ç»­ç›‘å¬
                if not self.listening:
                    break
            except Exception as e:
                if self.listening:
                    print(f"âš ï¸ ç›‘å¬é”™è¯¯: {e}")
                break
        
        print("ğŸ›‘ è¯­éŸ³è¯†åˆ«ç›‘å¬å·²åœæ­¢")
    
    def _listen_with_pattern_detection(self):
        """ä½¿ç”¨éŸ³é¢‘æ¨¡å¼æ£€æµ‹è¿›è¡Œç›‘å¬"""
        try:
            stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk,
                input_device_index=None
            )
            
            print("ğŸ¤ éŸ³é¢‘æ¨¡å¼ç›‘å¬å·²å¯åŠ¨...")
            
            while self.listening:
                try:
                    pcm = stream.read(self.chunk, exception_on_overflow=False)
                    pcm_data = np.frombuffer(pcm, dtype=np.int16)
                    
                    # æ£€æµ‹è¯­éŸ³æ´»åŠ¨
                    if self._detect_speech_pattern(pcm_data):
                        print(f"ğŸ¯ æ£€æµ‹åˆ°ç–‘ä¼¼å”¤é†’è¯æ¨¡å¼")
                        self._trigger_callback()
                    
                    time.sleep(0.01)
                    
                except Exception as e:
                    if self.listening:
                        print(f"âš ï¸ è¯»å–éŸ³é¢‘é”™è¯¯: {e}")
                    break
            
            stream.stop_stream()
            stream.close()
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ¨¡å¼ç›‘å¬é”™è¯¯: {e}")
        finally:
            print("ğŸ›‘ éŸ³é¢‘æ¨¡å¼ç›‘å¬å·²åœæ­¢")
    
    def _check_wake_word_match(self, text):
        """æ£€æŸ¥è¯†åˆ«çš„æ–‡æœ¬æ˜¯å¦åŒ¹é…å”¤é†’è¯"""
        text = text.replace(" ", "").lower()
        wake_word = self.wake_word.replace(" ", "").lower()
        
        # ç²¾ç¡®åŒ¹é…
        if wake_word in text:
            return True
        
        # æ¨¡ç³ŠåŒ¹é…ï¼ˆå¤„ç†è¯†åˆ«é”™è¯¯ï¼‰
        variations = [
            "ä½ å¥½å°æ™º", "ä½ å¥½å°çŸ¥", "ä½ å¥½å°å¿—", "ä½ å¥½å°åˆ¶",
            "ä½ å°æ™º", "ä½ å°çŸ¥", "ä½ å°å¿—", "ä½ å°åˆ¶",
            "å¥½å°æ™º", "å¥½å°çŸ¥", "å¥½å°å¿—", "å¥½å°åˆ¶",
            "å°æ™º", "å°çŸ¥", "å°å¿—", "å°åˆ¶"
        ]
        
        for variation in variations:
            if variation.lower() in text:
                return True
        
        return False
    
    def _detect_speech_pattern(self, pcm_data):
        """åŸºäºéŸ³é¢‘ç‰¹å¾æ£€æµ‹è¯­éŸ³æ¨¡å¼"""
        current_time = time.time()
        
        # è®¡ç®—éŸ³é¢‘ç‰¹å¾
        energy = np.sum(pcm_data.astype(np.float32) ** 2) / len(pcm_data)
        zero_crossings = self._count_zero_crossings(pcm_data)
        
        # æ£€æµ‹è¯­éŸ³å¼€å§‹
        if not self.speech_started and energy > self.energy_threshold:
            if zero_crossings > self.zero_crossing_threshold:
                self.speech_started = True
                self.speech_start_time = current_time
                self.detection_buffer = [pcm_data]
                return False
        
        # æ”¶é›†è¯­éŸ³æ•°æ®
        elif self.speech_started:
            self.detection_buffer.append(pcm_data)
            speech_duration = current_time - self.speech_start_time
            
            # æ£€æµ‹è¯­éŸ³ç»“æŸæˆ–è¶…æ—¶
            if (energy < self.energy_threshold * 0.5 or 
                speech_duration > self.max_speech_duration):
                
                self.speech_started = False
                
                # æ£€æŸ¥è¯­éŸ³æ—¶é•¿æ˜¯å¦åˆé€‚
                if (self.min_speech_duration <= speech_duration <= self.max_speech_duration and
                    current_time - self.last_detection_time > self.detection_cooldown):
                    
                    # åˆ†æè¯­éŸ³ç‰¹å¾
                    if self._analyze_speech_features():
                        self.last_detection_time = current_time
                        return True
                
                self.detection_buffer = []
        
        return False
    
    def _count_zero_crossings(self, signal):
        """è®¡ç®—é›¶äº¤å‰ç‡"""
        zero_crossings = 0
        for i in range(1, len(signal)):
            if (signal[i] >= 0) != (signal[i-1] >= 0):
                zero_crossings += 1
        return zero_crossings
    
    def _analyze_speech_features(self):
        """åˆ†æè¯­éŸ³ç‰¹å¾åˆ¤æ–­æ˜¯å¦ä¸ºç›®æ ‡å”¤é†’è¯"""
        if not self.detection_buffer:
            return False
        
        # åˆå¹¶éŸ³é¢‘æ•°æ®
        combined_audio = np.concatenate(self.detection_buffer)
        
        # è®¡ç®—æ•´ä½“ç‰¹å¾
        total_energy = np.sum(combined_audio.astype(np.float32) ** 2) / len(combined_audio)
        total_zero_crossings = self._count_zero_crossings(combined_audio)
        
        # ç®€å•çš„ç‰¹å¾åŒ¹é…ï¼ˆå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´é˜ˆå€¼ï¼‰
        # "ä½ å¥½å°æ™º" é€šå¸¸æœ‰4ä¸ªéŸ³èŠ‚ï¼Œèƒ½é‡åˆ†å¸ƒç›¸å¯¹å‡åŒ€
        
        # åˆ†æèƒ½é‡åˆ†å¸ƒ
        segment_size = len(combined_audio) // 4
        segment_energies = []
        
        for i in range(4):
            start = i * segment_size
            end = start + segment_size if i < 3 else len(combined_audio)
            segment = combined_audio[start:end]
            if len(segment) > 0:
                segment_energy = np.sum(segment.astype(np.float32) ** 2) / len(segment)
                segment_energies.append(segment_energy)
        
        if len(segment_energies) >= 3:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å¯¹å‡åŒ€çš„èƒ½é‡åˆ†å¸ƒï¼ˆå¤šéŸ³èŠ‚ç‰¹å¾ï¼‰
            energy_variance = np.var(segment_energies)
            mean_energy = np.mean(segment_energies)
            
            # æ ¹æ®ç»éªŒè°ƒæ•´çš„é˜ˆå€¼
            if (mean_energy > self.energy_threshold * 0.8 and
                energy_variance < mean_energy * 0.5 and
                total_zero_crossings > len(combined_audio) * 0.1):
                return True
        
        return False
    
    def _trigger_callback(self):
        """è§¦å‘å›è°ƒå‡½æ•°"""
        if self.callback:
            try:
                # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œå›è°ƒï¼Œé¿å…é˜»å¡ç›‘å¬
                callback_thread = threading.Thread(target=self.callback)
                callback_thread.daemon = True
                callback_thread.start()
            except Exception as e:
                print(f"âŒ æ‰§è¡Œå›è°ƒå‡½æ•°æ—¶å‡ºé”™: {e}")
    
    def stop(self):
        """åœæ­¢ç›‘å¬"""
        print("ğŸ›‘ æ­£åœ¨åœæ­¢å”¤é†’è¯ç›‘å¬...")
        self.listening = False
        
        if self.listen_thread and self.listen_thread.is_alive():
            self.listen_thread.join(timeout=2.0)
            if self.listen_thread.is_alive():
                print("âš ï¸ ç›‘å¬çº¿ç¨‹æœªèƒ½æ­£å¸¸åœæ­¢")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.stop()
        
        try:
            self.audio.terminate()
            print("âœ… PyAudio èµ„æºå·²æ¸…ç†")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç† PyAudio èµ„æºæ—¶å‡ºé”™: {e}")
    
    def set_sensitivity(self, sensitivity):
        """è®¾ç½®æ£€æµ‹çµæ•åº¦"""
        self.sensitivity = max(0.0, min(1.0, sensitivity))
        
        # è°ƒæ•´é˜ˆå€¼
        if self.detection_method == "pattern":
            base_threshold = 3000
            self.energy_threshold = base_threshold * (1.0 - self.sensitivity)
            print(f"ğŸ”§ æ£€æµ‹çµæ•åº¦å·²è®¾ç½®ä¸º: {self.sensitivity}")
            print(f"ğŸ”§ èƒ½é‡é˜ˆå€¼è°ƒæ•´ä¸º: {self.energy_threshold}")
        else:
            print(f"ğŸ”§ æ£€æµ‹çµæ•åº¦å·²è®¾ç½®ä¸º: {self.sensitivity}")
    
    def test_microphone(self):
        """æµ‹è¯•éº¦å…‹é£æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
        print("ğŸ¤ æ­£åœ¨æµ‹è¯•éº¦å…‹é£...")
        try:
            stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )
            
            print("ğŸ’¬ è¯·è¯´è¯æµ‹è¯•éº¦å…‹é£...")
            energies = []
            
            for i in range(50):  # æµ‹è¯•çº¦5ç§’
                data = stream.read(self.chunk, exception_on_overflow=False)
                pcm_data = np.frombuffer(data, dtype=np.int16)
                energy = np.sum(pcm_data.astype(np.float32) ** 2) / len(pcm_data)
                energies.append(energy)
                
                if i % 10 == 0:  # æ¯ç§’æ˜¾ç¤ºä¸€æ¬¡
                    print(f"ğŸ“Š éŸ³é¢‘èƒ½é‡: {energy:.2f}")
                
                time.sleep(0.1)
            
            stream.stop_stream()
            stream.close()
            
            avg_energy = np.mean(energies)
            max_energy = np.max(energies)
            
            print("âœ… éº¦å…‹é£æµ‹è¯•å®Œæˆ")
            print(f"ğŸ“ˆ å¹³å‡èƒ½é‡: {avg_energy:.2f}")
            print(f"ğŸ“ˆ æœ€å¤§èƒ½é‡: {max_energy:.2f}")
            
            if max_energy > 1000:
                print("âœ… éº¦å…‹é£å·¥ä½œæ­£å¸¸")
            else:
                print("âš ï¸ éº¦å…‹é£å¯èƒ½æœ‰é—®é¢˜ï¼Œèƒ½é‡å€¼è¿‡ä½")
            
        except Exception as e:
            print(f"âŒ éº¦å…‹é£æµ‹è¯•å¤±è´¥: {e}")


# è¾…åŠ©å‡½æ•°
def list_audio_devices():
    """åˆ—å‡ºå¯ç”¨çš„éŸ³é¢‘è®¾å¤‡"""
    audio = pyaudio.PyAudio()
    print("ğŸ§ å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡:")
    
    for i in range(audio.get_device_count()):
        device_info = audio.get_device_info_by_index(i)
        if device_info['maxInputChannels'] > 0:
            print(f"  ğŸ“± è®¾å¤‡ {i}: {device_info['name']} (è¾“å…¥é€šé“: {device_info['maxInputChannels']})")
    
    audio.terminate()


def install_dependencies():
    """æ˜¾ç¤ºå®‰è£…ä¾èµ–çš„è¯´æ˜"""
    print("ğŸ“¦ å®‰è£…å”¤é†’è¯æ£€æµ‹ä¾èµ–")
    print("=" * 50)
    print("å¿…éœ€ä¾èµ–:")
    print("pip install pyaudio numpy")
    print()
    print("å¯é€‰ä¾èµ–ï¼ˆæ¨èï¼Œæå‡å‡†ç¡®æ€§ï¼‰:")
    print("pip install SpeechRecognition")
    print()
    print("å¦‚æœé‡åˆ° pyaudio å®‰è£…é—®é¢˜:")
    print("macOS: brew install portaudio && pip install pyaudio")
    print("Ubuntu: sudo apt-get install portaudio19-dev && pip install pyaudio")
    print("Windows: pip install pipwin && pipwin install pyaudio")


# æµ‹è¯•å‡½æ•°
def test_wake_word_detector(wake_word="ä½ å¥½å°æ™º", test_duration=30):
    """æµ‹è¯•å”¤é†’è¯æ£€æµ‹å™¨"""
    def on_wake_word():
        print("ğŸ‰ æ£€æµ‹åˆ°å”¤é†’è¯å›è°ƒè¢«è§¦å‘!")
        print(f"âœ¨ æˆåŠŸæ£€æµ‹åˆ°: '{wake_word}'")
    
    print(f"ğŸ§ª å¼€å§‹æµ‹è¯•å”¤é†’è¯æ£€æµ‹å™¨")
    print(f"ğŸ¯ ç›®æ ‡å”¤é†’è¯: '{wake_word}'")
    print(f"â±ï¸ æµ‹è¯•æ—¶é•¿: {test_duration}ç§’")
    
    detector = WakeWordDetector(
        wake_word=wake_word,
        callback=on_wake_word,
        sensitivity=0.6
    )
    
    try:
        detector.start()
        
        print(f"ğŸ’¬ è¯·æ¸…æ™°åœ°è¯´å‡º: '{wake_word}'")
        print("ğŸ”‡ ä¿æŒç¯å¢ƒç›¸å¯¹å®‰é™ä»¥æé«˜æ£€æµ‹å‡†ç¡®æ€§")
        
        for remaining in range(test_duration, 0, -1):
            if remaining % 10 == 0:
                print(f"â° å‰©ä½™æµ‹è¯•æ—¶é—´: {remaining}ç§’")
            time.sleep(1)
        
    except KeyboardInterrupt:
        print("\nâ›” ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    finally:
        detector.cleanup()
        print("âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="å…è´¹å”¤é†’è¯æ£€æµ‹å™¨ - ä¸“é—¨æ£€æµ‹'ä½ å¥½å°æ™º'")
    parser.add_argument("--wake_word", type=str, default="ä½ å¥½å°æ™º",
                       help="æµ‹è¯•ç”¨çš„å”¤é†’è¯")
    parser.add_argument("--test_duration", type=int, default=30,
                       help="æµ‹è¯•æŒç»­æ—¶é—´(ç§’)")
    parser.add_argument("--list_devices", action="store_true",
                       help="åˆ—å‡ºå¯ç”¨çš„éŸ³é¢‘è®¾å¤‡")
    parser.add_argument("--test_mic", action="store_true",
                       help="æµ‹è¯•éº¦å…‹é£")
    parser.add_argument("--install", action="store_true",
                       help="æ˜¾ç¤ºä¾èµ–å®‰è£…è¯´æ˜")
    parser.add_argument("--sensitivity", type=float, default=0.6,
                       help="æ£€æµ‹çµæ•åº¦ (0.0-1.0)")
    
    args = parser.parse_args()
    
    if args.install:
        install_dependencies()
    elif args.list_devices:
        list_audio_devices()
    elif args.test_mic:
        detector = WakeWordDetector()
        detector.test_microphone()
        detector.cleanup()
    else:
        test_wake_word_detector(args.wake_word, args.test_duration)